{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4246862,"sourceType":"datasetVersion","datasetId":2502545}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nimport pathlib\nimport random\nimport string\nimport re\nimport numpy as np\n\nimport tensorflow.data as tf_data\nimport tensorflow.strings as tf_strings\n\nimport keras\nfrom keras import layers\nfrom keras import ops\nfrom keras.layers import TextVectorization\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T08:46:17.699608Z","iopub.execute_input":"2025-08-22T08:46:17.699820Z","iopub.status.idle":"2025-08-22T08:46:31.449986Z","shell.execute_reply.started":"2025-08-22T08:46:17.699796Z","shell.execute_reply":"2025-08-22T08:46:31.449430Z"}},"outputs":[{"name":"stderr","text":"2025-08-22 08:46:19.501994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755852379.718681      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755852379.783330      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Path to your CSV file\ntext_file = \"/kaggle/input/english-hindi-dataset/Dataset_English_Hindi.csv\"\n\n# Read CSV (assuming first column = English, second column = Hindi)\ndf = pd.read_csv(text_file, header=None, names=[\"en\", \"hi\"])\n\n# Preview data\nprint(df.head())\n\n# Extract English and Hindi sentences as lists\nenglish_texts = df[\"en\"].astype(str).tolist()\nhindi_texts   = df[\"hi\"].astype(str).tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T08:47:12.212899Z","iopub.execute_input":"2025-08-22T08:47:12.213613Z","iopub.status.idle":"2025-08-22T08:47:13.357916Z","shell.execute_reply.started":"2025-08-22T08:47:12.213578Z","shell.execute_reply":"2025-08-22T08:47:13.357244Z"}},"outputs":[{"name":"stdout","text":"        en      hi\n0  English   Hindi\n1    Help!   बचाओ!\n2    Jump.   उछलो.\n3    Jump.   कूदो.\n4    Jump.  छलांग.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Load CSV file (two columns: English, Hindi)\ntext_file = \"/kaggle/input/english-hindi-dataset/Dataset_English_Hindi.csv\"\ndf = pd.read_csv(text_file, header=None, names=[\"en\", \"hi\"])\n\n# Prepare sentence pairs with start/end tokens for Hindi\ntext_pairs = []\nfor eng, hin in zip(df[\"en\"], df[\"hi\"]):\n    hin = \"[start] \" + str(hin) + \" [end]\"\n    text_pairs.append((str(eng), hin))\n\nprint(\"Sample pairs:\")\nfor i in range(5):\n    print(text_pairs[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T08:47:56.613597Z","iopub.execute_input":"2025-08-22T08:47:56.614095Z","iopub.status.idle":"2025-08-22T08:47:57.464817Z","shell.execute_reply.started":"2025-08-22T08:47:56.614069Z","shell.execute_reply":"2025-08-22T08:47:57.464037Z"}},"outputs":[{"name":"stdout","text":"Sample pairs:\n('English', '[start] Hindi [end]')\n('Help!', '[start] बचाओ! [end]')\n('Jump.', '[start] उछलो. [end]')\n('Jump.', '[start] कूदो. [end]')\n('Jump.', '[start] छलांग. [end]')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import random\n\n# Shuffle the sentence pairs\nrandom.shuffle(text_pairs)\n\n# Split into train/val/test\nnum_val_samples = int(0.15 * len(text_pairs))\nnum_train_samples = len(text_pairs) - 2 * num_val_samples\n\ntrain_pairs = text_pairs[:num_train_samples]\nval_pairs   = text_pairs[num_train_samples : num_train_samples + num_val_samples]\ntest_pairs  = text_pairs[num_train_samples + num_val_samples :]\n\nprint(f\"{len(text_pairs)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")\nprint(f\"{len(test_pairs)} test pairs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T08:48:41.315467Z","iopub.execute_input":"2025-08-22T08:48:41.315784Z","iopub.status.idle":"2025-08-22T08:48:41.368891Z","shell.execute_reply.started":"2025-08-22T08:48:41.315765Z","shell.execute_reply":"2025-08-22T08:48:41.368272Z"}},"outputs":[{"name":"stdout","text":"130477 total pairs\n91335 training pairs\n19571 validation pairs\n19571 test pairs\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Characters to strip (punctuation)\nstrip_chars = string.punctuation + \"¿।\"   # added Hindi danda \"।\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\n# Vocabulary & sequence setup\nvocab_size = 15000\nsequence_length = 20\nbatch_size = 128\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:27:46.421604Z","iopub.execute_input":"2025-08-22T09:27:46.422292Z","iopub.status.idle":"2025-08-22T09:27:46.426192Z","shell.execute_reply.started":"2025-08-22T09:27:46.422268Z","shell.execute_reply":"2025-08-22T09:27:46.425376Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def custom_standardization(input_string):\n    # Lowercase + remove punctuation (but keep Devanagari intact)\n    lowercase = tf_strings.lower(input_string)\n    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n\n# English vectorizer\neng_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n)\n\n# Hindi vectorizer (target)\nhin_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length + 1,  # +1 for [end] token\n    standardize=custom_standardization,\n)\n\n# Prepare training data\ntrain_eng_texts = [pair[0] for pair in train_pairs]  # English\ntrain_hin_texts = [pair[1] for pair in train_pairs]  # Hindi (with [start] [end])\n\n# Adapt vectorizers on training texts\neng_vectorization.adapt(train_eng_texts)\nhin_vectorization.adapt(train_hin_texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:27:48.505629Z","iopub.execute_input":"2025-08-22T09:27:48.506076Z","iopub.status.idle":"2025-08-22T09:27:49.870261Z","shell.execute_reply.started":"2025-08-22T09:27:48.506052Z","shell.execute_reply":"2025-08-22T09:27:49.869707Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def format_dataset(eng, hin):\n    eng = eng_vectorization(eng)\n    hin = hin_vectorization(hin)\n    return (\n        {\n            \"encoder_inputs\": eng,\n            \"decoder_inputs\": hin[:, :-1],  # teacher forcing (shifted input)\n        },\n        hin[:, 1:],  # target (shifted output)\n    )\n\ndef make_dataset(pairs):\n    eng_texts, hin_texts = zip(*pairs)\n    eng_texts = list(eng_texts)\n    hin_texts = list(hin_texts)\n    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, hin_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    return dataset.cache().shuffle(2048).prefetch(16)\n\n# Training and validation datasets\ntrain_ds = make_dataset(train_pairs)\nval_ds   = make_dataset(val_pairs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T08:50:15.097030Z","iopub.execute_input":"2025-08-22T08:50:15.097622Z","iopub.status.idle":"2025-08-22T08:50:16.392011Z","shell.execute_reply.started":"2025-08-22T08:50:15.097597Z","shell.execute_reply":"2025-08-22T08:50:16.391431Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for inputs, targets in train_ds.take(1):\n    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n    print(f\"targets.shape: {targets.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:27:53.603946Z","iopub.execute_input":"2025-08-22T09:27:53.604412Z","iopub.status.idle":"2025-08-22T09:27:53.659049Z","shell.execute_reply.started":"2025-08-22T09:27:53.604371Z","shell.execute_reply":"2025-08-22T09:27:53.658522Z"}},"outputs":[{"name":"stdout","text":"inputs[\"encoder_inputs\"].shape: (64, 20)\ninputs[\"decoder_inputs\"].shape: (64, 20)\ntargets.shape: (64, 20)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import keras.ops as ops\n\nclass TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [\n                layers.Dense(dense_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n        else:\n            padding_mask = None\n\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"embed_dim\": self.embed_dim,\n                \"dense_dim\": self.dense_dim,\n                \"num_heads\": self.num_heads,\n            }\n        )\n        return config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:27:58.320826Z","iopub.execute_input":"2025-08-22T09:27:58.321316Z","iopub.status.idle":"2025-08-22T09:27:58.334298Z","shell.execute_reply.started":"2025-08-22T09:27:58.321292Z","shell.execute_reply":"2025-08-22T09:27:58.333572Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from keras import layers, ops\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n        super().__init__(**kwargs)\n        # Token embeddings (word embeddings)\n        self.token_embeddings = layers.Embedding(\n            input_dim=vocab_size, output_dim=embed_dim, mask_zero=True\n        )\n        # Positional embeddings (for sequence positions)\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n\n    def call(self, inputs):\n        # inputs.shape = (batch_size, sequence_length)\n        length = ops.shape(inputs)[-1]   # dynamic length\n        positions = ops.arange(start=0, stop=length, step=1)\n        positions = ops.expand_dims(positions, axis=0)   # shape (1, seq_len)\n        \n        # Embedding lookup\n        embedded_tokens = self.token_embeddings(inputs)           # (batch, seq_len, embed_dim)\n        embedded_positions = self.position_embeddings(positions)  # (1, seq_len, embed_dim)\n        \n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        # Mask pad tokens (id=0) for attention\n        return ops.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"sequence_length\": self.sequence_length,\n                \"vocab_size\": self.vocab_size,\n                \"embed_dim\": self.embed_dim,\n            }\n        )\n        return config\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:28:00.088615Z","iopub.execute_input":"2025-08-22T09:28:00.088883Z","iopub.status.idle":"2025-08-22T09:28:00.095787Z","shell.execute_reply.started":"2025-08-22T09:28:00.088862Z","shell.execute_reply":"2025-08-22T09:28:00.095097Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n\n        # Self-attention (masked, causal)\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        # Cross-attention (attends to encoder outputs)\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n\n        # Feed-forward network\n        self.dense_proj = keras.Sequential(\n            [\n                layers.Dense(latent_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n\n        # Layer norms\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n\n        self.supports_masking = True\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        # Step 1: Causal mask (prevent attending to future tokens)\n        causal_mask = self.get_causal_attention_mask(inputs)\n\n        # Step 2: Combine causal + padding mask\n        if mask is not None:\n            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")  # (batch, 1, seq_len)\n            combined_mask = ops.minimum(padding_mask, causal_mask)   # apply both\n        else:\n            combined_mask = causal_mask\n\n        # Step 3: Masked self-attention\n        attention_output_1 = self.attention_1(\n            query=inputs,\n            value=inputs,\n            key=inputs,\n            attention_mask=causal_mask,   # always apply causal mask here\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        # Step 4: Cross-attention with encoder outputs\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=combined_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        # Step 5: Feed-forward\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        \"\"\"Generates a lower-triangular (causal) mask\"\"\"\n        input_shape = ops.shape(inputs)\n        batch_size, seq_len = input_shape[0], input_shape[1]\n\n        i = ops.arange(seq_len)[:, None]\n        j = ops.arange(seq_len)\n        mask = ops.cast(i >= j, dtype=\"int32\")   # lower-triangular\n\n        mask = ops.reshape(mask, (1, seq_len, seq_len))  # (1, seq, seq)\n        mask = ops.tile(mask, (batch_size, 1, 1))        # (batch, seq, seq)\n        return mask\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"embed_dim\": self.embed_dim,\n                \"latent_dim\": self.latent_dim,\n                \"num_heads\": self.num_heads,\n            }\n        )\n        return config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:28:01.949720Z","iopub.execute_input":"2025-08-22T09:28:01.949979Z","iopub.status.idle":"2025-08-22T09:28:01.958922Z","shell.execute_reply.started":"2025-08-22T09:28:01.949960Z","shell.execute_reply":"2025-08-22T09:28:01.958181Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Hyperparameters\nembed_dim = 256\nlatent_dim = 2048\nnum_heads = 8\n\n# Encoder\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\nencoder = keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n\n# Decoder\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoder_state_inputs = keras.Input(shape=(None, embed_dim), name=\"encoder_state_inputs\")\n\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoder_state_inputs)\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n\ndecoder = keras.Model(\n    [decoder_inputs, encoder_state_inputs], decoder_outputs, name=\"decoder\"\n)\n\n# Full Transformer\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\ntransformer = keras.Model(\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n)\n\ntransformer.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:28:14.802411Z","iopub.execute_input":"2025-08-22T09:28:14.802703Z","iopub.status.idle":"2025-08-22T09:28:15.582693Z","shell.execute_reply.started":"2025-08-22T09:28:14.802682Z","shell.execute_reply":"2025-08-22T09:28:15.582133Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Number of epochs\nepochs = 60  # At least 30 for convergence\n\n# Print model summary\ntransformer.summary()\n\n# Compile the model\ntransformer.compile(\n    optimizer=\"rmsprop\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# Fit the model\nhistory = transformer.fit(\n    train_ds,\n    epochs=epochs,\n    validation_data=val_ds\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T09:28:29.482662Z","iopub.execute_input":"2025-08-22T09:28:29.483214Z","iopub.status.idle":"2025-08-22T10:14:00.064443Z","shell.execute_reply.started":"2025-08-22T09:28:29.483191Z","shell.execute_reply":"2025-08-22T10:14:00.063848Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1755854917.818545     101 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 357/1428\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 31ms/step - accuracy: 0.1044 - loss: 6.5658","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1755854938.656750      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1427/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1342 - loss: 5.9374","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1755854979.053730     100 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1755854980.052516      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 39ms/step - accuracy: 0.1342 - loss: 5.9368 - val_accuracy: 0.1890 - val_loss: 4.9013\nEpoch 2/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.1856 - loss: 4.9619 - val_accuracy: 0.2015 - val_loss: 4.6316\nEpoch 3/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2026 - loss: 4.6924 - val_accuracy: 0.2125 - val_loss: 4.4836\nEpoch 4/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2158 - loss: 4.5253 - val_accuracy: 0.2195 - val_loss: 4.4274\nEpoch 5/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2252 - loss: 4.4163 - val_accuracy: 0.2241 - val_loss: 4.3599\nEpoch 6/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2345 - loss: 4.3353 - val_accuracy: 0.2280 - val_loss: 4.3619\nEpoch 7/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2415 - loss: 4.2621 - val_accuracy: 0.2301 - val_loss: 4.3431\nEpoch 8/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2496 - loss: 4.2038 - val_accuracy: 0.2297 - val_loss: 4.3550\nEpoch 9/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2556 - loss: 4.1375 - val_accuracy: 0.2323 - val_loss: 4.3598\nEpoch 10/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.2635 - loss: 4.0746 - val_accuracy: 0.2336 - val_loss: 4.3705\nEpoch 11/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2702 - loss: 4.0129 - val_accuracy: 0.2367 - val_loss: 4.3804\nEpoch 12/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2778 - loss: 3.9508 - val_accuracy: 0.2381 - val_loss: 4.3805\nEpoch 13/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2830 - loss: 3.8986 - val_accuracy: 0.2371 - val_loss: 4.3952\nEpoch 14/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2914 - loss: 3.8341 - val_accuracy: 0.2390 - val_loss: 4.4167\nEpoch 15/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2982 - loss: 3.7652 - val_accuracy: 0.2388 - val_loss: 4.4238\nEpoch 16/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3044 - loss: 3.7152 - val_accuracy: 0.2407 - val_loss: 4.4088\nEpoch 17/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3114 - loss: 3.6654 - val_accuracy: 0.2418 - val_loss: 4.4474\nEpoch 18/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3165 - loss: 3.6185 - val_accuracy: 0.2429 - val_loss: 4.4441\nEpoch 19/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3224 - loss: 3.5810 - val_accuracy: 0.2418 - val_loss: 4.4738\nEpoch 20/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3258 - loss: 3.5455 - val_accuracy: 0.2415 - val_loss: 4.5160\nEpoch 21/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3309 - loss: 3.5013 - val_accuracy: 0.2420 - val_loss: 4.5028\nEpoch 22/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3352 - loss: 3.4610 - val_accuracy: 0.2446 - val_loss: 4.5619\nEpoch 23/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3398 - loss: 3.4275 - val_accuracy: 0.2434 - val_loss: 4.5473\nEpoch 24/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3435 - loss: 3.3935 - val_accuracy: 0.2442 - val_loss: 4.6085\nEpoch 25/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3473 - loss: 3.3651 - val_accuracy: 0.2439 - val_loss: 4.5777\nEpoch 26/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3506 - loss: 3.3492 - val_accuracy: 0.2434 - val_loss: 4.6196\nEpoch 27/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3538 - loss: 3.3168 - val_accuracy: 0.2458 - val_loss: 4.6509\nEpoch 28/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3568 - loss: 3.2892 - val_accuracy: 0.2464 - val_loss: 4.6286\nEpoch 29/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3595 - loss: 3.2608 - val_accuracy: 0.2454 - val_loss: 4.6475\nEpoch 30/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3645 - loss: 3.2359 - val_accuracy: 0.2448 - val_loss: 4.6769\nEpoch 31/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3670 - loss: 3.2099 - val_accuracy: 0.2474 - val_loss: 4.6674\nEpoch 32/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3683 - loss: 3.1872 - val_accuracy: 0.2440 - val_loss: 4.7030\nEpoch 33/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3733 - loss: 3.1550 - val_accuracy: 0.2453 - val_loss: 4.6841\nEpoch 34/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3756 - loss: 3.1314 - val_accuracy: 0.2443 - val_loss: 4.7038\nEpoch 35/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3806 - loss: 3.0953 - val_accuracy: 0.2459 - val_loss: 4.7873\nEpoch 36/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3816 - loss: 3.0786 - val_accuracy: 0.2461 - val_loss: 4.7851\nEpoch 37/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3858 - loss: 3.0482 - val_accuracy: 0.2455 - val_loss: 4.7325\nEpoch 38/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3879 - loss: 3.0306 - val_accuracy: 0.2463 - val_loss: 4.8215\nEpoch 39/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3905 - loss: 3.0039 - val_accuracy: 0.2460 - val_loss: 4.8641\nEpoch 40/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3934 - loss: 2.9804 - val_accuracy: 0.2469 - val_loss: 4.8341\nEpoch 41/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3958 - loss: 2.9613 - val_accuracy: 0.2469 - val_loss: 4.9078\nEpoch 42/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3985 - loss: 2.9457 - val_accuracy: 0.2490 - val_loss: 4.8592\nEpoch 43/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4005 - loss: 2.9216 - val_accuracy: 0.2499 - val_loss: 4.9027\nEpoch 44/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4032 - loss: 2.8942 - val_accuracy: 0.2461 - val_loss: 5.0005\nEpoch 45/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4051 - loss: 2.8816 - val_accuracy: 0.2459 - val_loss: 4.9349\nEpoch 46/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4085 - loss: 2.8615 - val_accuracy: 0.2477 - val_loss: 4.9761\nEpoch 47/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4088 - loss: 2.8470 - val_accuracy: 0.2452 - val_loss: 5.0258\nEpoch 48/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4109 - loss: 2.8383 - val_accuracy: 0.2485 - val_loss: 4.9890\nEpoch 49/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4139 - loss: 2.8170 - val_accuracy: 0.2464 - val_loss: 5.0786\nEpoch 50/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4155 - loss: 2.7850 - val_accuracy: 0.2469 - val_loss: 5.1255\nEpoch 51/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4175 - loss: 2.7801 - val_accuracy: 0.2481 - val_loss: 5.0659\nEpoch 52/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4183 - loss: 2.7676 - val_accuracy: 0.2429 - val_loss: 5.1850\nEpoch 53/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4206 - loss: 2.7476 - val_accuracy: 0.2408 - val_loss: 5.1773\nEpoch 54/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4210 - loss: 2.7418 - val_accuracy: 0.2449 - val_loss: 5.1088\nEpoch 55/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4226 - loss: 2.7269 - val_accuracy: 0.2457 - val_loss: 5.1140\nEpoch 56/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4249 - loss: 2.7193 - val_accuracy: 0.2475 - val_loss: 5.1789\nEpoch 57/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4256 - loss: 2.7062 - val_accuracy: 0.2467 - val_loss: 5.2462\nEpoch 58/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4271 - loss: 2.6957 - val_accuracy: 0.2484 - val_loss: 5.2190\nEpoch 59/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4307 - loss: 2.6704 - val_accuracy: 0.2452 - val_loss: 5.2502\nEpoch 60/60\n\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4293 - loss: 2.6706 - val_accuracy: 0.2459 - val_loss: 5.1852\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Get Hindi vocabulary and lookup dictionary\nhin_vocab = hin_vectorization.get_vocabulary()\nhin_index_lookup = dict(zip(range(len(hin_vocab)), hin_vocab))\n\nmax_decoded_sentence_length = 20\n\ndef decode_sequence(input_sentence):\n    # Vectorize the English input\n    tokenized_input_sentence = eng_vectorization([input_sentence])\n\n    # Start token for Hindi decoding\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n\n        # Predict next token\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n\n        # Convert prediction to token index\n        sampled_token_index = ops.convert_to_numpy(\n            ops.argmax(predictions[0, i, :])\n        ).item()\n\n        # Lookup Hindi word\n        sampled_token = hin_index_lookup[sampled_token_index]\n\n        # Append to the decoded sequence\n        decoded_sentence += \" \" + sampled_token\n\n        # Stop if end token reached\n        if sampled_token == \"[end]\":\n            break\n\n    return decoded_sentence\n\n\n# Test the translation on some random English sentences\ntest_eng_texts = [pair[0] for pair in test_pairs]\nfor _ in range(30):\n    input_sentence = random.choice(test_eng_texts)\n    translated = decode_sequence(input_sentence)\n    print(\"English:\", input_sentence)\n    print(\"Hindi Translation:\", translated)\n    print(\"=====================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T10:14:00.065734Z","iopub.execute_input":"2025-08-22T10:14:00.065990Z","iopub.status.idle":"2025-08-22T10:14:23.443897Z","shell.execute_reply.started":"2025-08-22T10:14:00.065973Z","shell.execute_reply":"2025-08-22T10:14:23.443314Z"}},"outputs":[{"name":"stdout","text":"English: Jawala Singh , a small farmer from Ludhiana district in Punjab , was not in such a miserable situation three years ago when he sold his tractor to repay a debt .\nHindi Translation: [start] [UNK] सिंह जिला देश में अभी तक तीन साल की उम्र से [UNK] में ही छोटी छोटी तीन महीने पहले\n=====================\nEnglish: (Applause)\nHindi Translation: [start] तालियाँ [end]\n=====================\nEnglish: and on painting day, we all gathered in Nyamirambo,\nHindi Translation: [start] और एक दिन हम सभी को [UNK] पर एक ही पूजा करते हैं [end]\n=====================\nEnglish: But on the whole the supremacy of thought and perception of unity in diversity are precious traits of the Indian mind and they are mirrored in all the cultures which had developed in India .\nHindi Translation: [start] किंतु इसी [UNK] की [UNK] और [UNK] की [UNK] [UNK] [UNK] की एकता का [UNK] के [UNK] के [UNK] से\n=====================\nEnglish: Where do they occur ?\nHindi Translation: [start] जहाँ वे उन्हें कहाँ पाई जाती हैं [end]\n=====================\nEnglish: the worlds percentage is more than 59.5%\nHindi Translation: [start] विश्व का प्रतिशत सबसे अधिक प्रतिशत है [end]\n=====================\nEnglish: I could go on giving examples:\nHindi Translation: [start] मैं [UNK] सकता हूँ कि उदाहरण देता हूँ [end]\n=====================\nEnglish: So the question arises,\nHindi Translation: [start] इसलिए बड़ी समस्या यह है कि [end]\n=====================\nEnglish: and engage them in a conversation\nHindi Translation: [start] और उन्हें एक [UNK] के लिए [UNK] से बातचीत करते हैं [end]\n=====================\nEnglish: to idiosyncratic, delicate and ephemeral.\nHindi Translation: [start] [UNK] और [UNK] से [UNK] तक [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n=====================\nEnglish: Has Tom left?\nHindi Translation: [start] पिछले समय चीन गया है [end]\n=====================\nEnglish: From ancient evidence found near north mumbai of Kandivali area, it looked that this Island cluster is established in Pasan Yug\nHindi Translation: [start] [UNK] [UNK] [UNK] क्षेत्र के उत्तरी मुंबई के आसपास के क्षेत्र से देखते थे कि इस क्षेत्र के [UNK] का\n=====================\nEnglish: He was covered in mud from head to foot.\nHindi Translation: [start] वे अपने शरीर से [UNK] से [UNK] था [end]\n=====================\nEnglish: Vedic-education.com\nHindi Translation: [start] [UNK] [end]\n=====================\nEnglish: In Abad Khan 's house , he was made conversant with the social habits and customs of Pathans so that his social and public behaviour was correct .\nHindi Translation: [start] [UNK] [UNK] [UNK] [UNK] का घर के [UNK] [UNK] [UNK] [UNK] [UNK] तथा [UNK] का और [UNK] की वजह उसके\n=====================\nEnglish: And just like my new dog, it was an idea that got bigger than I'd imagined.\nHindi Translation: [start] और मुझे अपनी बात का ऐसा लगता है कि जब मुझे कोई नया [UNK] से [UNK] था वह अभी मुझे\n=====================\nEnglish: There is the USA where people of different races and cultures , without any common history , were welded together simply by living in the same area and speaking the same language .\nHindi Translation: [start] हमारे देश में भिन्न भिन्न भिन्न [UNK] [UNK] तथा [UNK] एक दूसरे की [UNK] अनेक [UNK] थे तथा [UNK] भाषा\n=====================\nEnglish: Cultural aspects apart , many savants have studied old classics like the Pattu pattu , Silappadikaram , Manimekalai , Jivakachintamani as well as archaeological evidences and have given us fairly detailed accounts of these , yazhs .\nHindi Translation: [start] सांस्कृतिक [UNK] के अलावा शिक्षा भी कई अन्य [UNK] जैसे अनेक [UNK] ने साहित्य का विस्तार किया [UNK] [UNK] [UNK]\n=====================\nEnglish: Solar cooker (Solar cooker)\nHindi Translation: [start] सौर परिवर्तन [end]\n=====================\nEnglish: Earlier muslim sultans associated Hindu religion with the arab system of worshipping multiple deities, probably due to their poor understanding.\nHindi Translation: [start] मुस्लिम के विषय में हिन्दू धर्म से लगभग अब [UNK] की [UNK] का [UNK] हो क्योंकि उनके [UNK] की [UNK]\n=====================\nEnglish: Once we change those two things -\nHindi Translation: [start] एक बार तो हम दो चीज़ों को बदल देते हैं [end]\n=====================\nEnglish: For the promise-media sector.\nHindi Translation: [start] और [UNK] क्षेत्र [UNK] [end]\n=====================\nEnglish: he can't do a thing to it.\nHindi Translation: [start] वह [UNK] भी नहीं कर सकता [end]\n=====================\nEnglish: On 3rd April, 1973 Kapur used one modern, some heavy item and made first call to his competitor Dr.yole.S.Angle of Bell Laboratories from his invention handy mobile phone.\nHindi Translation: [start] [UNK] ने पहले तीस अप्रैल 1930 से एक निश्चित सम्राट बनायी और मुहम्मद इक़बाल ने [UNK] से स्थापना का अनुमान\n=====================\nEnglish: Thisrestriction does not apply to public accounts -LRB- Article 266 -RRB- .\nHindi Translation: [start] अनु [UNK] के राष्ट्रपति के या संविधान के संशोधन के लिए आय [UNK] नहीं पड़ती [end]\n=====================\nEnglish: The sign of any living thing lies in its capacity to grow and change .\nHindi Translation: [start] यह एक चीज़ अभी रहते हैं कि [UNK] और क्षमता में कोई भी बदलाव [end]\n=====================\nEnglish: The gist of the article ' These Remedies are not Enough ' , published on 9th June , was given to the court and jury .\nHindi Translation: [start] उनके भाषण पर विचार का [UNK] संविधान संशोधन किया गया और उन्हें [UNK] पर 6 [UNK] की [UNK] के लिए\n=====================\nEnglish: The three seator is the best transport for the travellers.\nHindi Translation: [start] तीन [UNK] के लोग [UNK] हैं [end]\n=====================\nEnglish: Don't lose your temper.\nHindi Translation: [start] अपने [UNK] [UNK] न [UNK] [end]\n=====================\nEnglish: In 1587, one Dutch troop also attacked at Yemen but defeated at the hand of Turkish Navy.\nHindi Translation: [start] इसके साथ एक के द्वारा [UNK] [UNK] में [UNK] [UNK] [UNK] विजय भी सीमित और [UNK] [UNK] [UNK] ने विजय\n=====================\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Function to decode a given English sentence into Hindi\ndef decode_sequence(input_sentence):\n    # Vectorize the English input\n    tokenized_input_sentence = eng_vectorization([input_sentence])\n\n    # Start token for Hindi decoding\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n\n        # Predict next token\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n\n        # Convert prediction to token index\n        sampled_token_index = ops.convert_to_numpy(\n            ops.argmax(predictions[0, i, :])\n        ).item()\n\n        # Lookup Hindi word\n        sampled_token = hin_index_lookup[sampled_token_index]\n\n        # Append to the decoded sequence\n        decoded_sentence += \" \" + sampled_token\n\n        # Stop if end token reached\n        if sampled_token == \"[end]\":\n            break\n\n    # Clean up [start] and [end] tokens for readability\n    return decoded_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n\n\n# -----------------------------\n# Try your own custom sentences\n# -----------------------------\ncustom_sentences = [\n    \"How are you?\",\n    \"I am going to school.\",\n    \"What is your name?\",\n    \"Today is a beautiful day.\",\n    \"i love you\"\n]\n\nfor input_sentence in custom_sentences:\n    translated = decode_sequence(input_sentence)\n    print(\"English:\", input_sentence)\n    print(\"Hindi Translation:\", translated)\n    print(\"=====================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T10:20:21.227029Z","iopub.execute_input":"2025-08-22T10:20:21.227319Z","iopub.status.idle":"2025-08-22T10:20:22.746445Z","shell.execute_reply.started":"2025-08-22T10:20:21.227297Z","shell.execute_reply":"2025-08-22T10:20:22.745886Z"}},"outputs":[{"name":"stdout","text":"English: How are you?\nHindi Translation: आप क्यों\n=====================\nEnglish: I am going to school.\nHindi Translation: मैं स्कूल जा रहा हूँ\n=====================\nEnglish: What is your name?\nHindi Translation: आपका नाम क्या है\n=====================\nEnglish: Today is a beautiful day.\nHindi Translation: आज बहुत अच्छे पक्षी हैं\n=====================\nEnglish: i love you\nHindi Translation: मुझे पसंद है\n=====================\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"transformer.save(\"eng_hin_transformer.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T10:23:01.035931Z","iopub.execute_input":"2025-08-22T10:23:01.036300Z","iopub.status.idle":"2025-08-22T10:23:01.377512Z","shell.execute_reply.started":"2025-08-22T10:23:01.036268Z","shell.execute_reply":"2025-08-22T10:23:01.376965Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import gradio as gr\nfrom keras import ops\n\n# Function to decode a given English sentence into Hindi\ndef decode_sequence(input_sentence):\n    # Vectorize the English input\n    tokenized_input_sentence = eng_vectorization([input_sentence])\n\n    # Start token for Hindi decoding\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n\n        # Predict next token\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n\n        # Convert prediction to token index\n        sampled_token_index = ops.convert_to_numpy(\n            ops.argmax(predictions[0, i, :])\n        ).item()\n\n        # Lookup Hindi word\n        sampled_token = hin_index_lookup[sampled_token_index]\n\n        # Append to the decoded sequence\n        decoded_sentence += \" \" + sampled_token\n\n        # Stop if end token reached\n        if sampled_token == \"[end]\":\n            break\n\n    # Clean up [start] and [end] tokens for readability\n    return decoded_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n\n\n# Wrap with Gradio\ndef translate(input_text):\n    return decode_sequence(input_text)\n\ndemo = gr.Interface(\n    fn=translate,\n    inputs=gr.Textbox(lines=2, placeholder=\"Enter an English sentence...\"),\n    outputs=\"text\",\n    title=\"English → Hindi Translator\",\n    description=\"Enter an English sentence and get its Hindi translation.\"\n)\n\ndemo.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T10:35:50.520242Z","iopub.execute_input":"2025-08-22T10:35:50.520532Z","iopub.status.idle":"2025-08-22T10:35:51.105641Z","shell.execute_reply.started":"2025-08-22T10:35:50.520510Z","shell.execute_reply":"2025-08-22T10:35:51.104847Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7863\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://438cce0fbb993aca6d.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://438cce0fbb993aca6d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'decoder' (of type Functional) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Created dataset file at: .gradio/flagged/dataset1.csv\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}