{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-22T08:46:17.699820Z",
     "iopub.status.busy": "2025-08-22T08:46:17.699608Z",
     "iopub.status.idle": "2025-08-22T08:46:31.449986Z",
     "shell.execute_reply": "2025-08-22T08:46:31.449430Z",
     "shell.execute_reply.started": "2025-08-22T08:46:17.699796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 08:46:19.501994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755852379.718681      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755852379.783330      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:47:12.213613Z",
     "iopub.status.busy": "2025-08-22T08:47:12.212899Z",
     "iopub.status.idle": "2025-08-22T08:47:13.357916Z",
     "shell.execute_reply": "2025-08-22T08:47:13.357244Z",
     "shell.execute_reply.started": "2025-08-22T08:47:12.213578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        en      hi\n",
      "0  English   Hindi\n",
      "1    Help!   बचाओ!\n",
      "2    Jump.   उछलो.\n",
      "3    Jump.   कूदो.\n",
      "4    Jump.  छलांग.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "text_file = \"/kaggle/input/english-hindi-dataset/Dataset_English_Hindi.csv\"\n",
    "\n",
    "# Read CSV (assuming first column = English, second column = Hindi)\n",
    "df = pd.read_csv(text_file, header=None, names=[\"en\", \"hi\"])\n",
    "\n",
    "# Preview data\n",
    "print(df.head())\n",
    "\n",
    "# Extract English and Hindi sentences as lists\n",
    "english_texts = df[\"en\"].astype(str).tolist()\n",
    "hindi_texts   = df[\"hi\"].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:47:56.614095Z",
     "iopub.status.busy": "2025-08-22T08:47:56.613597Z",
     "iopub.status.idle": "2025-08-22T08:47:57.464817Z",
     "shell.execute_reply": "2025-08-22T08:47:57.464037Z",
     "shell.execute_reply.started": "2025-08-22T08:47:56.614069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pairs:\n",
      "('English', '[start] Hindi [end]')\n",
      "('Help!', '[start] बचाओ! [end]')\n",
      "('Jump.', '[start] उछलो. [end]')\n",
      "('Jump.', '[start] कूदो. [end]')\n",
      "('Jump.', '[start] छलांग. [end]')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file (two columns: English, Hindi)\n",
    "text_file = \"/kaggle/input/english-hindi-dataset/Dataset_English_Hindi.csv\"\n",
    "df = pd.read_csv(text_file, header=None, names=[\"en\", \"hi\"])\n",
    "\n",
    "# Prepare sentence pairs with start/end tokens for Hindi\n",
    "text_pairs = []\n",
    "for eng, hin in zip(df[\"en\"], df[\"hi\"]):\n",
    "    hin = \"[start] \" + str(hin) + \" [end]\"\n",
    "    text_pairs.append((str(eng), hin))\n",
    "\n",
    "print(\"Sample pairs:\")\n",
    "for i in range(5):\n",
    "    print(text_pairs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:48:41.315784Z",
     "iopub.status.busy": "2025-08-22T08:48:41.315467Z",
     "iopub.status.idle": "2025-08-22T08:48:41.368891Z",
     "shell.execute_reply": "2025-08-22T08:48:41.368272Z",
     "shell.execute_reply.started": "2025-08-22T08:48:41.315765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130477 total pairs\n",
      "91335 training pairs\n",
      "19571 validation pairs\n",
      "19571 test pairs\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Shuffle the sentence pairs\n",
    "random.shuffle(text_pairs)\n",
    "\n",
    "# Split into train/val/test\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs   = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs  = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:27:46.422292Z",
     "iopub.status.busy": "2025-08-22T09:27:46.421604Z",
     "iopub.status.idle": "2025-08-22T09:27:46.426192Z",
     "shell.execute_reply": "2025-08-22T09:27:46.425376Z",
     "shell.execute_reply.started": "2025-08-22T09:27:46.422268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Characters to strip (punctuation)\n",
    "strip_chars = string.punctuation + \"¿।\"   # added Hindi danda \"।\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "# Vocabulary & sequence setup\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:27:48.506076Z",
     "iopub.status.busy": "2025-08-22T09:27:48.505629Z",
     "iopub.status.idle": "2025-08-22T09:27:49.870261Z",
     "shell.execute_reply": "2025-08-22T09:27:49.869707Z",
     "shell.execute_reply.started": "2025-08-22T09:27:48.506052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "    # Lowercase + remove punctuation (but keep Devanagari intact)\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "# English vectorizer\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Hindi vectorizer (target)\n",
    "hin_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,  # +1 for [end] token\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]  # English\n",
    "train_hin_texts = [pair[1] for pair in train_pairs]  # Hindi (with [start] [end])\n",
    "\n",
    "# Adapt vectorizers on training texts\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "hin_vectorization.adapt(train_hin_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:15.097622Z",
     "iopub.status.busy": "2025-08-22T08:50:15.097030Z",
     "iopub.status.idle": "2025-08-22T08:50:16.392011Z",
     "shell.execute_reply": "2025-08-22T08:50:16.391431Z",
     "shell.execute_reply.started": "2025-08-22T08:50:15.097597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_dataset(eng, hin):\n",
    "    eng = eng_vectorization(eng)\n",
    "    hin = hin_vectorization(hin)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\": hin[:, :-1],  # teacher forcing (shifted input)\n",
    "        },\n",
    "        hin[:, 1:],  # target (shifted output)\n",
    "    )\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, hin_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    hin_texts = list(hin_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, hin_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "# Training and validation datasets\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds   = make_dataset(val_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:27:53.604412Z",
     "iopub.status.busy": "2025-08-22T09:27:53.603946Z",
     "iopub.status.idle": "2025-08-22T09:27:53.659049Z",
     "shell.execute_reply": "2025-08-22T09:27:53.658522Z",
     "shell.execute_reply.started": "2025-08-22T09:27:53.604371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:27:58.321316Z",
     "iopub.status.busy": "2025-08-22T09:27:58.320826Z",
     "iopub.status.idle": "2025-08-22T09:27:58.334298Z",
     "shell.execute_reply": "2025-08-22T09:27:58.333572Z",
     "shell.execute_reply.started": "2025-08-22T09:27:58.321292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras.ops as ops\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"dense_dim\": self.dense_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:28:00.088883Z",
     "iopub.status.busy": "2025-08-22T09:28:00.088615Z",
     "iopub.status.idle": "2025-08-22T09:28:00.095787Z",
     "shell.execute_reply": "2025-08-22T09:28:00.095097Z",
     "shell.execute_reply.started": "2025-08-22T09:28:00.088862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras import layers, ops\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Token embeddings (word embeddings)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim, mask_zero=True\n",
    "        )\n",
    "        # Positional embeddings (for sequence positions)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs.shape = (batch_size, sequence_length)\n",
    "        length = ops.shape(inputs)[-1]   # dynamic length\n",
    "        positions = ops.arange(start=0, stop=length, step=1)\n",
    "        positions = ops.expand_dims(positions, axis=0)   # shape (1, seq_len)\n",
    "        \n",
    "        # Embedding lookup\n",
    "        embedded_tokens = self.token_embeddings(inputs)           # (batch, seq_len, embed_dim)\n",
    "        embedded_positions = self.position_embeddings(positions)  # (1, seq_len, embed_dim)\n",
    "        \n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Mask pad tokens (id=0) for attention\n",
    "        return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:28:01.949979Z",
     "iopub.status.busy": "2025-08-22T09:28:01.949720Z",
     "iopub.status.idle": "2025-08-22T09:28:01.958922Z",
     "shell.execute_reply": "2025-08-22T09:28:01.958181Z",
     "shell.execute_reply.started": "2025-08-22T09:28:01.949960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Self-attention (masked, causal)\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        # Cross-attention (attends to encoder outputs)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        # Feed-forward network\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Layer norms\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        # Step 1: Causal mask (prevent attending to future tokens)\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        # Step 2: Combine causal + padding mask\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")  # (batch, 1, seq_len)\n",
    "            combined_mask = ops.minimum(padding_mask, causal_mask)   # apply both\n",
    "        else:\n",
    "            combined_mask = causal_mask\n",
    "\n",
    "        # Step 3: Masked self-attention\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask,   # always apply causal mask here\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        # Step 4: Cross-attention with encoder outputs\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=combined_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        # Step 5: Feed-forward\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        \"\"\"Generates a lower-triangular (causal) mask\"\"\"\n",
    "        input_shape = ops.shape(inputs)\n",
    "        batch_size, seq_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        i = ops.arange(seq_len)[:, None]\n",
    "        j = ops.arange(seq_len)\n",
    "        mask = ops.cast(i >= j, dtype=\"int32\")   # lower-triangular\n",
    "\n",
    "        mask = ops.reshape(mask, (1, seq_len, seq_len))  # (1, seq, seq)\n",
    "        mask = ops.tile(mask, (batch_size, 1, 1))        # (batch, seq, seq)\n",
    "        return mask\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:28:14.802703Z",
     "iopub.status.busy": "2025-08-22T09:28:14.802411Z",
     "iopub.status.idle": "2025-08-22T09:28:15.582693Z",
     "shell.execute_reply": "2025-08-22T09:28:15.582133Z",
     "shell.execute_reply.started": "2025-08-22T09:28:14.802682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Hyperparameters\n",
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoder_state_inputs = keras.Input(shape=(None, embed_dim), name=\"encoder_state_inputs\")\n",
    "\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoder_state_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "decoder = keras.Model(\n",
    "    [decoder_inputs, encoder_state_inputs], decoder_outputs, name=\"decoder\"\n",
    ")\n",
    "\n",
    "# Full Transformer\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n",
    "\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:28:29.483214Z",
     "iopub.status.busy": "2025-08-22T09:28:29.482662Z",
     "iopub.status.idle": "2025-08-22T10:14:00.064443Z",
     "shell.execute_reply": "2025-08-22T10:14:00.063848Z",
     "shell.execute_reply.started": "2025-08-22T09:28:29.483191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755854917.818545     101 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 357/1428\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 31ms/step - accuracy: 0.1044 - loss: 6.5658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755854938.656750      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1427/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1342 - loss: 5.9374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755854979.053730     100 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1755854980.052516      99 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 39ms/step - accuracy: 0.1342 - loss: 5.9368 - val_accuracy: 0.1890 - val_loss: 4.9013\n",
      "Epoch 2/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.1856 - loss: 4.9619 - val_accuracy: 0.2015 - val_loss: 4.6316\n",
      "Epoch 3/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2026 - loss: 4.6924 - val_accuracy: 0.2125 - val_loss: 4.4836\n",
      "Epoch 4/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2158 - loss: 4.5253 - val_accuracy: 0.2195 - val_loss: 4.4274\n",
      "Epoch 5/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2252 - loss: 4.4163 - val_accuracy: 0.2241 - val_loss: 4.3599\n",
      "Epoch 6/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2345 - loss: 4.3353 - val_accuracy: 0.2280 - val_loss: 4.3619\n",
      "Epoch 7/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2415 - loss: 4.2621 - val_accuracy: 0.2301 - val_loss: 4.3431\n",
      "Epoch 8/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2496 - loss: 4.2038 - val_accuracy: 0.2297 - val_loss: 4.3550\n",
      "Epoch 9/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2556 - loss: 4.1375 - val_accuracy: 0.2323 - val_loss: 4.3598\n",
      "Epoch 10/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.2635 - loss: 4.0746 - val_accuracy: 0.2336 - val_loss: 4.3705\n",
      "Epoch 11/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2702 - loss: 4.0129 - val_accuracy: 0.2367 - val_loss: 4.3804\n",
      "Epoch 12/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2778 - loss: 3.9508 - val_accuracy: 0.2381 - val_loss: 4.3805\n",
      "Epoch 13/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2830 - loss: 3.8986 - val_accuracy: 0.2371 - val_loss: 4.3952\n",
      "Epoch 14/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.2914 - loss: 3.8341 - val_accuracy: 0.2390 - val_loss: 4.4167\n",
      "Epoch 15/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2982 - loss: 3.7652 - val_accuracy: 0.2388 - val_loss: 4.4238\n",
      "Epoch 16/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3044 - loss: 3.7152 - val_accuracy: 0.2407 - val_loss: 4.4088\n",
      "Epoch 17/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3114 - loss: 3.6654 - val_accuracy: 0.2418 - val_loss: 4.4474\n",
      "Epoch 18/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3165 - loss: 3.6185 - val_accuracy: 0.2429 - val_loss: 4.4441\n",
      "Epoch 19/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3224 - loss: 3.5810 - val_accuracy: 0.2418 - val_loss: 4.4738\n",
      "Epoch 20/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3258 - loss: 3.5455 - val_accuracy: 0.2415 - val_loss: 4.5160\n",
      "Epoch 21/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3309 - loss: 3.5013 - val_accuracy: 0.2420 - val_loss: 4.5028\n",
      "Epoch 22/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3352 - loss: 3.4610 - val_accuracy: 0.2446 - val_loss: 4.5619\n",
      "Epoch 23/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3398 - loss: 3.4275 - val_accuracy: 0.2434 - val_loss: 4.5473\n",
      "Epoch 24/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3435 - loss: 3.3935 - val_accuracy: 0.2442 - val_loss: 4.6085\n",
      "Epoch 25/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3473 - loss: 3.3651 - val_accuracy: 0.2439 - val_loss: 4.5777\n",
      "Epoch 26/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3506 - loss: 3.3492 - val_accuracy: 0.2434 - val_loss: 4.6196\n",
      "Epoch 27/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3538 - loss: 3.3168 - val_accuracy: 0.2458 - val_loss: 4.6509\n",
      "Epoch 28/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3568 - loss: 3.2892 - val_accuracy: 0.2464 - val_loss: 4.6286\n",
      "Epoch 29/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3595 - loss: 3.2608 - val_accuracy: 0.2454 - val_loss: 4.6475\n",
      "Epoch 30/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3645 - loss: 3.2359 - val_accuracy: 0.2448 - val_loss: 4.6769\n",
      "Epoch 31/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3670 - loss: 3.2099 - val_accuracy: 0.2474 - val_loss: 4.6674\n",
      "Epoch 32/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3683 - loss: 3.1872 - val_accuracy: 0.2440 - val_loss: 4.7030\n",
      "Epoch 33/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3733 - loss: 3.1550 - val_accuracy: 0.2453 - val_loss: 4.6841\n",
      "Epoch 34/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3756 - loss: 3.1314 - val_accuracy: 0.2443 - val_loss: 4.7038\n",
      "Epoch 35/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3806 - loss: 3.0953 - val_accuracy: 0.2459 - val_loss: 4.7873\n",
      "Epoch 36/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3816 - loss: 3.0786 - val_accuracy: 0.2461 - val_loss: 4.7851\n",
      "Epoch 37/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.3858 - loss: 3.0482 - val_accuracy: 0.2455 - val_loss: 4.7325\n",
      "Epoch 38/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3879 - loss: 3.0306 - val_accuracy: 0.2463 - val_loss: 4.8215\n",
      "Epoch 39/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.3905 - loss: 3.0039 - val_accuracy: 0.2460 - val_loss: 4.8641\n",
      "Epoch 40/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.3934 - loss: 2.9804 - val_accuracy: 0.2469 - val_loss: 4.8341\n",
      "Epoch 41/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3958 - loss: 2.9613 - val_accuracy: 0.2469 - val_loss: 4.9078\n",
      "Epoch 42/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.3985 - loss: 2.9457 - val_accuracy: 0.2490 - val_loss: 4.8592\n",
      "Epoch 43/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4005 - loss: 2.9216 - val_accuracy: 0.2499 - val_loss: 4.9027\n",
      "Epoch 44/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4032 - loss: 2.8942 - val_accuracy: 0.2461 - val_loss: 5.0005\n",
      "Epoch 45/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4051 - loss: 2.8816 - val_accuracy: 0.2459 - val_loss: 4.9349\n",
      "Epoch 46/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4085 - loss: 2.8615 - val_accuracy: 0.2477 - val_loss: 4.9761\n",
      "Epoch 47/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4088 - loss: 2.8470 - val_accuracy: 0.2452 - val_loss: 5.0258\n",
      "Epoch 48/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4109 - loss: 2.8383 - val_accuracy: 0.2485 - val_loss: 4.9890\n",
      "Epoch 49/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4139 - loss: 2.8170 - val_accuracy: 0.2464 - val_loss: 5.0786\n",
      "Epoch 50/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4155 - loss: 2.7850 - val_accuracy: 0.2469 - val_loss: 5.1255\n",
      "Epoch 51/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4175 - loss: 2.7801 - val_accuracy: 0.2481 - val_loss: 5.0659\n",
      "Epoch 52/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4183 - loss: 2.7676 - val_accuracy: 0.2429 - val_loss: 5.1850\n",
      "Epoch 53/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4206 - loss: 2.7476 - val_accuracy: 0.2408 - val_loss: 5.1773\n",
      "Epoch 54/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.4210 - loss: 2.7418 - val_accuracy: 0.2449 - val_loss: 5.1088\n",
      "Epoch 55/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4226 - loss: 2.7269 - val_accuracy: 0.2457 - val_loss: 5.1140\n",
      "Epoch 56/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 32ms/step - accuracy: 0.4249 - loss: 2.7193 - val_accuracy: 0.2475 - val_loss: 5.1789\n",
      "Epoch 57/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4256 - loss: 2.7062 - val_accuracy: 0.2467 - val_loss: 5.2462\n",
      "Epoch 58/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.4271 - loss: 2.6957 - val_accuracy: 0.2484 - val_loss: 5.2190\n",
      "Epoch 59/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4307 - loss: 2.6704 - val_accuracy: 0.2452 - val_loss: 5.2502\n",
      "Epoch 60/60\n",
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.4293 - loss: 2.6706 - val_accuracy: 0.2459 - val_loss: 5.1852\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs\n",
    "epochs = 60  # At least 30 for convergence\n",
    "\n",
    "# Print model summary\n",
    "transformer.summary()\n",
    "\n",
    "# Compile the model\n",
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = transformer.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T10:14:00.065990Z",
     "iopub.status.busy": "2025-08-22T10:14:00.065734Z",
     "iopub.status.idle": "2025-08-22T10:14:23.443897Z",
     "shell.execute_reply": "2025-08-22T10:14:23.443314Z",
     "shell.execute_reply.started": "2025-08-22T10:14:00.065973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Jawala Singh , a small farmer from Ludhiana district in Punjab , was not in such a miserable situation three years ago when he sold his tractor to repay a debt .\n",
      "Hindi Translation: [start] [UNK] सिंह जिला देश में अभी तक तीन साल की उम्र से [UNK] में ही छोटी छोटी तीन महीने पहले\n",
      "=====================\n",
      "English: (Applause)\n",
      "Hindi Translation: [start] तालियाँ [end]\n",
      "=====================\n",
      "English: and on painting day, we all gathered in Nyamirambo,\n",
      "Hindi Translation: [start] और एक दिन हम सभी को [UNK] पर एक ही पूजा करते हैं [end]\n",
      "=====================\n",
      "English: But on the whole the supremacy of thought and perception of unity in diversity are precious traits of the Indian mind and they are mirrored in all the cultures which had developed in India .\n",
      "Hindi Translation: [start] किंतु इसी [UNK] की [UNK] और [UNK] की [UNK] [UNK] [UNK] की एकता का [UNK] के [UNK] के [UNK] से\n",
      "=====================\n",
      "English: Where do they occur ?\n",
      "Hindi Translation: [start] जहाँ वे उन्हें कहाँ पाई जाती हैं [end]\n",
      "=====================\n",
      "English: the worlds percentage is more than 59.5%\n",
      "Hindi Translation: [start] विश्व का प्रतिशत सबसे अधिक प्रतिशत है [end]\n",
      "=====================\n",
      "English: I could go on giving examples:\n",
      "Hindi Translation: [start] मैं [UNK] सकता हूँ कि उदाहरण देता हूँ [end]\n",
      "=====================\n",
      "English: So the question arises,\n",
      "Hindi Translation: [start] इसलिए बड़ी समस्या यह है कि [end]\n",
      "=====================\n",
      "English: and engage them in a conversation\n",
      "Hindi Translation: [start] और उन्हें एक [UNK] के लिए [UNK] से बातचीत करते हैं [end]\n",
      "=====================\n",
      "English: to idiosyncratic, delicate and ephemeral.\n",
      "Hindi Translation: [start] [UNK] और [UNK] से [UNK] तक [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "=====================\n",
      "English: Has Tom left?\n",
      "Hindi Translation: [start] पिछले समय चीन गया है [end]\n",
      "=====================\n",
      "English: From ancient evidence found near north mumbai of Kandivali area, it looked that this Island cluster is established in Pasan Yug\n",
      "Hindi Translation: [start] [UNK] [UNK] [UNK] क्षेत्र के उत्तरी मुंबई के आसपास के क्षेत्र से देखते थे कि इस क्षेत्र के [UNK] का\n",
      "=====================\n",
      "English: He was covered in mud from head to foot.\n",
      "Hindi Translation: [start] वे अपने शरीर से [UNK] से [UNK] था [end]\n",
      "=====================\n",
      "English: Vedic-education.com\n",
      "Hindi Translation: [start] [UNK] [end]\n",
      "=====================\n",
      "English: In Abad Khan 's house , he was made conversant with the social habits and customs of Pathans so that his social and public behaviour was correct .\n",
      "Hindi Translation: [start] [UNK] [UNK] [UNK] [UNK] का घर के [UNK] [UNK] [UNK] [UNK] [UNK] तथा [UNK] का और [UNK] की वजह उसके\n",
      "=====================\n",
      "English: And just like my new dog, it was an idea that got bigger than I'd imagined.\n",
      "Hindi Translation: [start] और मुझे अपनी बात का ऐसा लगता है कि जब मुझे कोई नया [UNK] से [UNK] था वह अभी मुझे\n",
      "=====================\n",
      "English: There is the USA where people of different races and cultures , without any common history , were welded together simply by living in the same area and speaking the same language .\n",
      "Hindi Translation: [start] हमारे देश में भिन्न भिन्न भिन्न [UNK] [UNK] तथा [UNK] एक दूसरे की [UNK] अनेक [UNK] थे तथा [UNK] भाषा\n",
      "=====================\n",
      "English: Cultural aspects apart , many savants have studied old classics like the Pattu pattu , Silappadikaram , Manimekalai , Jivakachintamani as well as archaeological evidences and have given us fairly detailed accounts of these , yazhs .\n",
      "Hindi Translation: [start] सांस्कृतिक [UNK] के अलावा शिक्षा भी कई अन्य [UNK] जैसे अनेक [UNK] ने साहित्य का विस्तार किया [UNK] [UNK] [UNK]\n",
      "=====================\n",
      "English: Solar cooker (Solar cooker)\n",
      "Hindi Translation: [start] सौर परिवर्तन [end]\n",
      "=====================\n",
      "English: Earlier muslim sultans associated Hindu religion with the arab system of worshipping multiple deities, probably due to their poor understanding.\n",
      "Hindi Translation: [start] मुस्लिम के विषय में हिन्दू धर्म से लगभग अब [UNK] की [UNK] का [UNK] हो क्योंकि उनके [UNK] की [UNK]\n",
      "=====================\n",
      "English: Once we change those two things -\n",
      "Hindi Translation: [start] एक बार तो हम दो चीज़ों को बदल देते हैं [end]\n",
      "=====================\n",
      "English: For the promise-media sector.\n",
      "Hindi Translation: [start] और [UNK] क्षेत्र [UNK] [end]\n",
      "=====================\n",
      "English: he can't do a thing to it.\n",
      "Hindi Translation: [start] वह [UNK] भी नहीं कर सकता [end]\n",
      "=====================\n",
      "English: On 3rd April, 1973 Kapur used one modern, some heavy item and made first call to his competitor Dr.yole.S.Angle of Bell Laboratories from his invention handy mobile phone.\n",
      "Hindi Translation: [start] [UNK] ने पहले तीस अप्रैल 1930 से एक निश्चित सम्राट बनायी और मुहम्मद इक़बाल ने [UNK] से स्थापना का अनुमान\n",
      "=====================\n",
      "English: Thisrestriction does not apply to public accounts -LRB- Article 266 -RRB- .\n",
      "Hindi Translation: [start] अनु [UNK] के राष्ट्रपति के या संविधान के संशोधन के लिए आय [UNK] नहीं पड़ती [end]\n",
      "=====================\n",
      "English: The sign of any living thing lies in its capacity to grow and change .\n",
      "Hindi Translation: [start] यह एक चीज़ अभी रहते हैं कि [UNK] और क्षमता में कोई भी बदलाव [end]\n",
      "=====================\n",
      "English: The gist of the article ' These Remedies are not Enough ' , published on 9th June , was given to the court and jury .\n",
      "Hindi Translation: [start] उनके भाषण पर विचार का [UNK] संविधान संशोधन किया गया और उन्हें [UNK] पर 6 [UNK] की [UNK] के लिए\n",
      "=====================\n",
      "English: The three seator is the best transport for the travellers.\n",
      "Hindi Translation: [start] तीन [UNK] के लोग [UNK] हैं [end]\n",
      "=====================\n",
      "English: Don't lose your temper.\n",
      "Hindi Translation: [start] अपने [UNK] [UNK] न [UNK] [end]\n",
      "=====================\n",
      "English: In 1587, one Dutch troop also attacked at Yemen but defeated at the hand of Turkish Navy.\n",
      "Hindi Translation: [start] इसके साथ एक के द्वारा [UNK] [UNK] में [UNK] [UNK] [UNK] विजय भी सीमित और [UNK] [UNK] [UNK] ने विजय\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "# Get Hindi vocabulary and lookup dictionary\n",
    "hin_vocab = hin_vectorization.get_vocabulary()\n",
    "hin_index_lookup = dict(zip(range(len(hin_vocab)), hin_vocab))\n",
    "\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    # Vectorize the English input\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "\n",
    "    # Start token for Hindi decoding\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n",
    "        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n",
    "\n",
    "        # Predict next token\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Convert prediction to token index\n",
    "        sampled_token_index = ops.convert_to_numpy(\n",
    "            ops.argmax(predictions[0, i, :])\n",
    "        ).item()\n",
    "\n",
    "        # Lookup Hindi word\n",
    "        sampled_token = hin_index_lookup[sampled_token_index]\n",
    "\n",
    "        # Append to the decoded sequence\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Stop if end token reached\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "# Test the translation on some random English sentences\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(30):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(\"English:\", input_sentence)\n",
    "    print(\"Hindi Translation:\", translated)\n",
    "    print(\"=====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T10:20:21.227319Z",
     "iopub.status.busy": "2025-08-22T10:20:21.227029Z",
     "iopub.status.idle": "2025-08-22T10:20:22.746445Z",
     "shell.execute_reply": "2025-08-22T10:20:22.745886Z",
     "shell.execute_reply.started": "2025-08-22T10:20:21.227297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: How are you?\n",
      "Hindi Translation: आप क्यों\n",
      "=====================\n",
      "English: I am going to school.\n",
      "Hindi Translation: मैं स्कूल जा रहा हूँ\n",
      "=====================\n",
      "English: What is your name?\n",
      "Hindi Translation: आपका नाम क्या है\n",
      "=====================\n",
      "English: Today is a beautiful day.\n",
      "Hindi Translation: आज बहुत अच्छे पक्षी हैं\n",
      "=====================\n",
      "English: i love you\n",
      "Hindi Translation: मुझे पसंद है\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "# Function to decode a given English sentence into Hindi\n",
    "def decode_sequence(input_sentence):\n",
    "    # Vectorize the English input\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "\n",
    "    # Start token for Hindi decoding\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n",
    "        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n",
    "\n",
    "        # Predict next token\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Convert prediction to token index\n",
    "        sampled_token_index = ops.convert_to_numpy(\n",
    "            ops.argmax(predictions[0, i, :])\n",
    "        ).item()\n",
    "\n",
    "        # Lookup Hindi word\n",
    "        sampled_token = hin_index_lookup[sampled_token_index]\n",
    "\n",
    "        # Append to the decoded sequence\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Stop if end token reached\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    # Clean up [start] and [end] tokens for readability\n",
    "    return decoded_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Try your own custom sentences\n",
    "# -----------------------------\n",
    "custom_sentences = [\n",
    "    \"How are you?\",\n",
    "    \"I am going to school.\",\n",
    "    \"What is your name?\",\n",
    "    \"Today is a beautiful day.\",\n",
    "    \"i love you\"\n",
    "]\n",
    "\n",
    "for input_sentence in custom_sentences:\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(\"English:\", input_sentence)\n",
    "    print(\"Hindi Translation:\", translated)\n",
    "    print(\"=====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T10:23:01.036300Z",
     "iopub.status.busy": "2025-08-22T10:23:01.035931Z",
     "iopub.status.idle": "2025-08-22T10:23:01.377512Z",
     "shell.execute_reply": "2025-08-22T10:23:01.376965Z",
     "shell.execute_reply.started": "2025-08-22T10:23:01.036268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transformer.save(\"eng_hin_transformer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T10:35:50.520532Z",
     "iopub.status.busy": "2025-08-22T10:35:50.520242Z",
     "iopub.status.idle": "2025-08-22T10:35:51.105641Z",
     "shell.execute_reply": "2025-08-22T10:35:51.104847Z",
     "shell.execute_reply.started": "2025-08-22T10:35:50.520510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from keras import ops\n",
    "\n",
    "# Function to decode a given English sentence into Hindi\n",
    "def decode_sequence(input_sentence):\n",
    "    # Vectorize the English input\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "\n",
    "    # Start token for Hindi decoding\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        # Vectorize current decoded Hindi sequence (excluding last token for prediction step)\n",
    "        tokenized_target_sentence = hin_vectorization([decoded_sentence])[:, :-1]\n",
    "\n",
    "        # Predict next token\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Convert prediction to token index\n",
    "        sampled_token_index = ops.convert_to_numpy(\n",
    "            ops.argmax(predictions[0, i, :])\n",
    "        ).item()\n",
    "\n",
    "        # Lookup Hindi word\n",
    "        sampled_token = hin_index_lookup[sampled_token_index]\n",
    "\n",
    "        # Append to the decoded sequence\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Stop if end token reached\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    # Clean up [start] and [end] tokens for readability\n",
    "    return decoded_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n",
    "\n",
    "\n",
    "# Wrap with Gradio\n",
    "def translate(input_text):\n",
    "    return decode_sequence(input_text)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter an English sentence...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"English → Hindi Translator\",\n",
    "    description=\"Enter an English sentence and get its Hindi translation.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2502545,
     "sourceId": 4246862,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
